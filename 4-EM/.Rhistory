matplot(ZZ)
head(ZZ)
head(rowSums(ZZ))
plot.mixture(model, YY)
plot.classification(model, YY)
set.seed(1)
model.2 <- fit.em.gauss(2, YY, n.tries=20, verbose=FALSE)
plot.mixture(model.2, YY)
df(model.2)
# aic.gm(model, YY)
bic.gm(model.2, YY)
llk(model.2, YY)
M.2.VVV <- Mclust(YY, G=2, modelNames='VVV')
M.2.VVV$df
M.2.VVV$bic
M.2.VVV$loglik
plot(M.2, what='classification')
plot(M.2$classification)
set.seed(1)
my.bic <- ic.mod.sel(7, 20, do.plot=TRUE)$bic
set.seed(1)
mc.bic <- mclustBIC(YY, modelNames='VVV')
cat('Our BICs:\n')
print(my.bic)
cat('Mclust\'s BICs:\n')
print(as.numeric(mc.bic))
matplot(cbind(mc.bic[1:7], my.bic), pch=c(1,2), type='b')
set.seed(1)
model <- fit.em.gauss(2, YY, 20, verbose=FALSE)
ZZ <- matrix(unlist(model$zz), 272, 2)
matplot(ZZ)
head(ZZ)
head(rowSums(ZZ))
matplot(ZZ)
plot.classification(model, YY)
set.seed(1)
model <- fit.em.gauss(2, YY, 20, verbose=FALSE)
ZZ <- matrix(unlist(model$zz), 272, 2)
head(ZZ)
head(rowSums(ZZ))
matplot(ZZ)
plot.classification(model, YY)
plot(M.2, what='classification')
plot(M.2$classification)
set.seed(1)
model.2 <- fit.em.gauss(2, YY, n.tries=20, verbose=FALSE)
plot.mixture(model.2, YY)
df(model.2)
bic.gm(model.2, YY)
llk(model.2, YY)
M.2.VVV <- Mclust(YY, G=2, modelNames='VVV')
M.2.VVV$df
M.2.VVV$bic
M.2.VVV$loglik
set.seed(1)
my.bic <- ic.mod.sel(7, 20, do.plot=TRUE)$bic
set.seed(1)
mc.bic <- mclustBIC(YY, modelNames='VVV')
cat('Our BICs:\n')
print(my.bic)
cat('Mclust\'s BICs:\n')
print(as.numeric(mc.bic))
matplot(cbind(mc.bic[1:7], my.bic), pch=c(1,2), type='b')
plot(M.2, what='classification')
library('mclust')
BIC <- mclustBIC(YY)
plot(BIC)
M <- Mclust(YY, x=BIC)
summary(M, paramteters=TRUE)
summary(BIC)
BIC <- mclustBIC(YY)
M <- Mclust(YY, x=BIC)
model.3 <- fit.em.gauss(2, YY, n.tries=20, verbose=FALSE)
plot.clustCombi(model.3)
plot.clustCombi(model.3, YY)
plot.classification(model.3, YY)
model.3 <- fit.em.gauss(, YY, n.tries=20, verbose=FALSE)
model.3 <- fit.em.gauss(3, YY, n.tries=20, verbose=FALSE)
plot.classification(model.3, YY)
plot.classification(fit.em.gauss(4, YY, n.tries=20, verbose=FALSE), YY)
plot.classification(fit.em.gauss(5, YY, n.tries=20, verbose=FALSE), YY)
plot.classification <- function(model, YY, plot.densities=TRUE) {
N <- nrow(YY)
m <- length(model$pp)
ZZ <- matrix(unlist(model$zz), N, m)
xlim <- c(min(YY[,1]), max(YY[,1]))
ylim <- c(min(YY[,2]), max(YY[,2]))
if (plot.densities) {
plot.mixture(model, YY)
} else {
plot(YY, type='n')
}
class.labels <- apply(ZZ, 1, which.max)
for (ell in 1:m) {
par(new=TRUE)
plot(YY[class.labels==ell,], col=(1+ell), xlab='', ylab='', xlim=xlim, ylim=ylim, axes=FALSE)
}
}
set.seed(1)
model <- fit.em.gauss(2, YY, 20, verbose=FALSE)
ZZ <- matrix(unlist(model$zz), 272, 2)
head(ZZ)
head(rowSums(ZZ))
# matplot(ZZ)
plot.classification(model, YY)
par(mfcol=c(2,2))
par(mfcol=c(2,2))
for (ell in 2:5) {
set.seed(1)
plot.classification(fit.em.gauss(ell, YY, 30, verbose=FALSE), YY, plot.densities=FALSE)
}
par(mfrow=c(2,2))
for (ell in 2:5) {
set.seed(1)
plot.classification(fit.em.gauss(ell, YY, 30, verbose=FALSE), YY, plot.densities=FALSE)
}
par(mfcol=c(1,1))
plot.classification <- function(model, YY, plot.densities=TRUE, ...) {
N <- nrow(YY)
m <- length(model$pp)
ZZ <- matrix(unlist(model$zz), N, m)
xlim <- c(min(YY[,1]), max(YY[,1]))
ylim <- c(min(YY[,2]), max(YY[,2]))
if (plot.densities) {
plot.mixture(model, YY, ...)
} else {
plot(YY, type='n', ...)
}
class.labels <- apply(ZZ, 1, which.max)
for (ell in 1:m) {
par(new=TRUE)
plot(YY[class.labels==ell,], col=(1+ell), xlab='', ylab='', xlim=xlim, ylim=ylim, axes=FALSE)
}
}
set.seed(1)
model <- fit.em.gauss(2, YY, 20, verbose=FALSE)
ZZ <- matrix(unlist(model$zz), 272, 2)
head(ZZ)
head(rowSums(ZZ))
# matplot(ZZ)
plot.classification(model, YY)
par(mfrow=c(2,2))
for (ell in 2:5) {
set.seed(1)
plot.classification(fit.em.gauss(ell, YY, 30, verbose=FALSE), YY, plot.densities=FALSE, main=paste('m=', ell))
}
par(mfcol=c(1,1))
plot.classification <- function(model, YY, plot.densities=TRUE) {
N <- nrow(YY)
m <- length(model$pp)
ZZ <- matrix(unlist(model$zz), N, m)
xlim <- c(min(YY[,1]), max(YY[,1]))
ylim <- c(min(YY[,2]), max(YY[,2]))
if (plot.densities) {
plot.mixture(model, YY, main=paste('m =', m))
} else {
plot(YY, type='n', main=paste('m =', m))
}
class.labels <- apply(ZZ, 1, which.max)
for (ell in 1:m) {
par(new=TRUE)
plot(YY[class.labels==ell,], col=(1+ell), xlab='', ylab='', xlim=xlim, ylim=ylim, axes=FALSE)
}
}
set.seed(1)
model <- fit.em.gauss(2, YY, 20, verbose=FALSE)
ZZ <- matrix(unlist(model$zz), 272, 2)
head(ZZ)
head(rowSums(ZZ))
# matplot(ZZ)
plot.classification(model, YY)
par(mfrow=c(2,2))
for (ell in 2:5) {
set.seed(1)
plot.classification(fit.em.gauss(ell, YY, 30, verbose=FALSE), YY, plot.densities=FALSE)
}
par(mfcol=c(1,1))
set.seed(1)
par(mfrow=c(2,2))
for (ell in 2:5) {
set.seed(1)
M <- Mclust(YY, G=ell, modelNames='VVV')
plot(M, what='classification')
}
par(mfcol=c(1,1))
set.seed(1)
par(mfrow=c(2,2))
for (ell in 2:5) {
set.seed(1)
M <- Mclust(YY, G=ell, modelNames='VVV')
plot(M, what='classification', main=paste('m =', ell))
}
par(mfcol=c(1,1))
set.seed(1)
par(mfrow=c(2,2))
for (ell in 2:5) {
set.seed(1)
M <- Mclust(YY, G=ell, modelNames='VVV')
# plot(M, what='classification')
plot(M.2.VVV, what='uncertainty')
}
par(mfcol=c(1,1))
set.seed(1)
par(mfrow=c(2,2))
for (ell in 2:5) {
set.seed(1)
M <- Mclust(YY, G=ell, modelNames='VVV')
# plot(M, what='classification')
plot(M, what='uncertainty')
}
par(mfcol=c(1,1))
set.seed(1)
par(mfrow=c(2,2))
for (ell in 2:5) {
set.seed(1)
M <- Mclust(YY, G=ell, modelNames='VVV')
plot(M, what='classification')
}
par(mfcol=c(1,1))
par(mfrow=c(2,2))
for (ell in 2:5) {
set.seed(1)
M <- Mclust(YY, G=ell, modelNames='VVV')
plot(M, what='uncertainty')
}
par(mfcol=c(1,1))
par(mfrow=c(2,2))
for (ell in 2:5) {
set.seed(1)
M <- Mclust(YY, G=ell, modelNames='VVV')
plot(M, what='density', type = 'image', col = 'dodgerblue3', grid = 100)
# plot(M.2.VVV, what='density', type = 'persp')
}
par(mfcol=c(1,1))
par(mfrow=c(2,2))
for (ell in 2:5) {
set.seed(1)
plot.classification(fit.em.gauss(ell, YY, 30, verbose=FALSE), YY, plot.densities=FALSE)
}
par(mfcol=c(1,1))
set.seed(1)
par(mfrow=c(2,2))
for (ell in 2:5) {
set.seed(1)
M <- Mclust(YY, G=ell, modelNames='VVV')
plot(M, what='classification')
}
par(mfcol=c(1,1))
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
library('mvtnorm')
plot.mixture <- function(model, YY, ...) {
plot(YY, ...)
mmu <- model$mmu
SS <- model$SS
m <- length(mmu)
xx <- seq(min(YY[,1]), max(YY[,1]), by=.1)
yy <- seq(min(YY[,2]), max(YY[,2]), by=.1)
for (ell in 1:m) {
contour(xx, yy,
outer(xx, yy, function(xx, yy) dmvnorm(cbind(xx, yy), mmu[[ell]], SS[[ell]])),
add=T, col=1+ell%%7)
}
}
YY <- as.matrix(faithful)
par(mfrow=c(1,2))
# boxplot(YY$eruptions)
# boxplot(YY$waiting)
par(mfrow=c(1,1))
plot(YY)
# Chunk 3
llk <- function(model, YY) {
mmu <- model$mmu
SS <- model$SS
pp <- model$pp
m <- length(mmu)
N <- nrow(YY)
PPHI <- matrix(0, N, m)
for (ell in 1:m) {
PPHI[,ell] <- dmvnorm(YY, mean=mmu[[ell]], sigma=SS[[ell]])
}
sum(log(PPHI %*% pp))
}
em.gauss <- function(m, YY, llk.diff.eps=0.1, do.plot=FALSE, verbose=FALSE) {
d <- ncol(YY)
N <- nrow(YY)
phi <- dmvnorm
mmu <- list()
SS <- list()
ww <- list()
zz <- list()
llk.prev <- -Inf
llk.hist <- NULL
# Initialization
# TODO: Split the data into m clusters at random; calculate mmu, SS, pp for each cluster
for (ell in 1:m) {
# pick two data points at random
mmu[[ell]] <- sample(as.data.frame(t(YY)), 1)[[1]]
SS[[ell]] <- cov(YY)
}
pp <- rep(1/m, m)
if (do.plot) {
plot.mixture(list(pp=pp, mmu=mmu, SS=SS), YY, main=paste('n.iter =', 0))
}
n.iter <- 1
repeat {
# Expectation
PPHI <- matrix(0, N, m)
for (ell in 1:m) {
PPHI[,ell] <- phi(YY, mean=mmu[[ell]], sigma=SS[[ell]])
}
for (ell in 1:m) {
zz[[ell]] <- pp[[ell]] * PPHI[,ell]  / PPHI %*% pp
}
for (ell in 1:m) {
ww[[ell]] <- zz[[ell]] / sum(zz[[ell]])
}
# Maximization
for (ell in 1:m) {
mmu[[ell]] <- as.vector(t(YY) %*% ww[[ell]])
pp[[ell]] <- sum(zz[[ell]]) / N
# FIXME: vectorize
for (i1 in 1:d) {
for (i2 in 1:d) {
SS[[ell]][i1, i2] <- sum(ww[[ell]] * (YY[, i1] - mmu[[ell]][i1]) * (YY[, i2] - mmu[[ell]][i2]))
}
}
}
llk.cur <- llk(list(pp=pp, mmu=mmu, SS=SS), YY)
llk.diff <- abs(llk.cur - llk.prev)
if (verbose) {
cat('# ', n.iter, ' LLK = ', llk.cur, ' (', llk.diff, ')\n', sep='')
}
llk.hist <- c(llk.hist, llk.cur)
if (do.plot) {
plot.mixture(list(pp=pp, mmu=mmu, SS=SS), YY, main=paste('n.iter =', n.iter))
}
if (llk.diff < llk.diff.eps) {
if (do.plot) {
plot(llk.hist, type='o', col='blue', main='Log likelihood', xlab='n.iter')
}
return(list(pp=pp, mmu=mmu, SS=SS, zz=zz, llk=llk.cur, llk.hist=llk.hist))
} else {
llk.prev <- llk.cur
n.iter <- n.iter + 1
}
}
}
# Chunk 4
set.seed(2)
model.2 <- em.gauss(2, YY, do.plot=TRUE, verbose=TRUE)
model.2$pp
model.2$mmu
model.2$SS
# Chunk 5
set.seed(1)
model.3 <- em.gauss(3, YY, do.plot=TRUE, verbose=TRUE)
# Chunk 6
fit.em.gauss <- function(m, YY, n.tries=10, verbose=FALSE) {
prev.llk <- -Inf
model.best <- NULL
for (n.iter in 1:n.tries) {
if (verbose) {
cat('= Fitting model', n.iter, '...\n')
}
model <- em.gauss(m, YY, verbose=verbose)
if (model$llk > prev.llk) {
model.best <- model
}
}
return(model)
}
set.seed(1)
model <- fit.em.gauss(3, YY, verbose=TRUE)
# Chunk 7
df <- function(model) {
m <- length(model$mmu)
d <- length(model$mmu[[1]])
(m - 1) + m * d + m * d*(d+1) / 2
}
aic.gm <- function(model, YY) {
2 * (llk(model, YY) - df(model))
}
bic.gm <- function(model, YY) {
N <- nrow(YY)
2 * llk(model, YY) - df(model) * log(N)
}
# Chunk 8
model <- em.gauss(3, YY, do.plot=FALSE)
df(model)
aic.gm(model, YY)
bic.gm(model, YY)
# Chunk 9
ic.mod.sel <- function(m.max, n.tries=10, do.plot=FALSE) {
aic <- numeric(m.max)
bic <- numeric(m.max)
for (m in 1:m.max) {
cat('m =', m, '\n')
model <- fit.em.gauss(m, YY, n.tries=n.tries, verbose=FALSE)
# model <- em.gauss(m, YY)
aic[m] <- aic.gm(model, YY)
bic[m] <- bic.gm(model, YY)
}
if (do.plot) {
matplot(cbind(aic, bic), type='b', pch=c(1,2), col=c('blue', 'red'), lty=c('solid'),
main='', xlab='m')
}
legend("topleft", bty = "n",
legend = c('AIC', 'BIC'),
col = c('blue', 'red'),
lty = c('solid', 'solid'))
return(list(aic=aic, bic=bic))
}
# Chunk 10
set.seed(1)
ic.mod.sel(7, 20, do.plot=TRUE)
plot(cars)
knitr::opts_chunk$set(echo = TRUE)
library('mvtnorm')
plot.mixture <- function(model, YY, ...) {
plot(YY, ...)
mmu <- model$mmu
SS <- model$SS
m <- length(mmu)
xx <- seq(min(YY[,1]), max(YY[,1]), by=.1)
yy <- seq(min(YY[,2]), max(YY[,2]), by=.1)
for (ell in 1:m) {
contour(xx, yy,
outer(xx, yy, function(xx, yy) dmvnorm(cbind(xx, yy), mmu[[ell]], SS[[ell]])),
add=T, col=1+ell%%7)
}
}
YY <- as.matrix(faithful)
par(mfrow=c(1,2))
# boxplot(YY$eruptions)
# boxplot(YY$waiting)
par(mfrow=c(1,1))
plot(YY)
library('mclust')
set.seed(1)
par(mfrow=c(2,2))
for (ell in 2:5) {
set.seed(1)
M <- Mclust(YY, G=ell, modelNames='VVV')
plot(M, what='classification')
}
par(mfcol=c(1,1))
par(mfrow=c(2,2))
for (ell in 2:5) {
set.seed(1)
M <- Mclust(YY, G=ell, modelNames='VVV')
plot(M, what='uncertainty')
}
par(mfcol=c(1,1))
par(mfrow=c(2,2))
for (ell in 2:5) {
set.seed(1)
M <- Mclust(YY, G=ell, modelNames='VVV')
plot(M, what='density', type = 'image', col = 'dodgerblue3', grid = 100)
# plot(M.2.VVV, what='density', type = 'persp')
}
for (ell in 2:5) {
set.seed(1)
M <- Mclust(YY, G=ell, modelNames='VVV')
plot(M, what='density', type = 'image', col = 'dodgerblue3', grid = 100)
# plot(M.2.VVV, what='density', type = 'persp')
}
par(mfcol=c(1,1))
par(mfrow=c(2,2))
for (ell in 2:5) {
set.seed(1)
M <- Mclust(YY, G=ell, modelNames='VVV')
plot(M, what='uncertainty')
}
for (ell in 2:5) {
set.seed(1)
M <- Mclust(YY, G=ell, modelNames='VVV')
plot(M, what='uncertainty')
}
par(mfcol=c(1,1))
set.seed(1)
par(mfrow=c(2,2))
for (ell in 2:5) {
set.seed(1)
M <- Mclust(YY, G=ell, modelNames='VVV')
plot(M, what='classification')
}
par(mfcol=c(1,1))
par(mfrow=c(2,2))
for (ell in 2:5) {
set.seed(1)
M <- Mclust(YY, G=ell, modelNames='VVV')
plot(M, what='uncertainty')
}
par(mfcol=c(1,1))
par(mfrow=c(2,2))
for (ell in 2:5) {
set.seed(1)
M <- Mclust(YY, G=ell, modelNames='VVV')
plot(M, what='density', type = 'image', col = 'dodgerblue3', grid = 100)
# plot(M.2.VVV, what='density', type = 'persp')
}
par(mfcol=c(1,1))
M.2.VVV <- Mclust(YY, G=2, modelNames='VVV')
M.2.VVV$df
M.2.VVV$bic
M.2.VVV$loglik
M.2.VVV <- Mclust(YY, G=2, modelNames='VVV')
M.2.VVV$df
M.2.VVV$bic
M.2.VVV$loglik
